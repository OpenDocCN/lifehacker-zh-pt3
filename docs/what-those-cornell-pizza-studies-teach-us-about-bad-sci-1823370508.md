# 康奈尔披萨研究告诉我们什么是糟糕的科学

> 原文：<https://lifehacker.com/what-those-cornell-pizza-studies-teach-us-about-bad-sci-1823370508>

草率的统计数据和不当的研究行为并不新鲜，但很少有人能清楚地了解可疑数据是如何变成点击标题的。我们现在有了关于康奈尔大学食品科学家布莱恩·万辛克的最新报道，值得花一分钟来看看他被指控使用 的 [欺诈研究技术到底错在哪里。](https://lifehacker.com/some-of-our-best-food-hacks-may-be-wrong-1794125552) 



我们去年提到万辛克的研究受到质疑，从康奈尔裁定草率但不欺诈的四项披萨自助餐研究开始。从那以后，他的更多作品被研究，并且看起来越来越模糊。本周末，Buzzfeed 的 Stephanie M. Lee(与 [无关，我们自己的斯蒂芬妮·李](https://kinja.com/superlee7) ) [发表了来自 Wansink 的研究团队](https://www.buzzfeed.com/stephaniemlee/brian-wansink-cornell-p-hacking?utm_term=.kpQqwamX1#.kfM72PYmn) 的电子邮件，为*而不是*如何做科学提供了一个很好的教训。

在我们进入细节之前，重要的一点是:科学仍然有效。糟糕的研究是存在的，人们也会误解或误报好的研究。(任何读过我们的 [剂量的现实](https://lifehacker.com/c/dose-of-reality) 帖子的人都明白这一点。)棘手的是，要分辨谁在做合法的、设计良好的研究，并用适当的统计技术处理它们，而谁只是在模仿那些做法。现实世界是两者的混合体。所以，不要失去信心！但是一定要保持怀疑。以下是一些可能出错的地方:

### P-hacking 可以“发现”并不存在的相关性

在完成一项研究后，你必须问的一个基本问题是:我到底有没有发现什么？假设你想知道人们更喜欢蛋糕还是馅饼。如果没有人有偏好，你可以在下一次聚会上列出这两种甜点，你会期望从每种甜点中消失的数量相同。

但是假设人们吃了 31 片蛋糕和 30 片馅饼。这种差异可能不足以让你得出你的群体有偏好的结论。用研究术语来说，这种差异在统计上并不显著。

那么，如何判断一个结果是否有意义呢？一种方法是计算你偶然看到结果的可能性。如果低于 5 %,那么经验法则是人们会相信你的结果是有效的。

统计学家称这个数字为 p 值，如果它低于 0.05(这是 5%的另一种说法)，那么你可以称你的结果是有意义的。p 值有其局限性，它们*并不*意味着你已经确定你的结果是由于一个真实的影响而非偶然。但是它们为您提供了一个起点，让您知道哪些数据不应该被打扰。如果你的 *p* 超过 0.05，你的数字可能没有意义。

所以，问题来了。如果你观察一组完全随机的数据，你会发现有 5%的时间有“显著的”p 值。如果你要观察一大堆变量，直到一个 p 值脱颖而出，你可以挑选那些不寻常的数据点，假装它们有意义。 [XKCD 用漫画形式](https://xkcd.com/882/) 很好地总结了这一点:软糖可能不会导致痤疮，但如果你对 20 种不同口味的软糖进行相同的测试，你可能会碰巧发现其中一种口味呈阳性结果。

如果你是一个细心的科学家，你会确保在 [分析你的结果时牢记这个陷阱](https://en.wikipedia.org/wiki/Multiple_comparisons_problem) 。(一个简单的方法是:选择一个小于 0.05 的数字作为 p 值的临界值。)

但是如果你不是一个细心的科学家，这不是一个陷阱而是一个机会。你可以运行任何你喜欢的研究，如果它足够大，你总是会发现一些看起来有意义的结果！利用这种统计现象被称为“p-hacking”或“数据钓鱼”。如果你用这种方式发布结果，你可能会发布很多假阳性。

当我阅读研究论文时，只要我注意到一项研究正在研究许多不同的变量，我就会按 Ctrl-F 在页面中搜索短语“多重比较”，看看是否有一节研究人员解释了他们如何处理这种情况。由于统计学不是我的专业领域，如果我需要对他们的分析质量做出判断，我会问外部专家。但是，如果研究人员正在进行多重比较，甚至根本不提这个问题，那就是一个很大的危险信号。

### 优秀的科学家在收集数据之前会问问题，而不是相反

每个实验都是一个问题。理想情况下，你收集数据作为回答你的问题的一种方式，你会看到数据告诉你什么。

但是如果你用 p-hack，你可能只是在收集随机数据，然后在事后编造数据可能意味着什么的故事。这在科学上相当于看到你的神奇 8 号球给出了一个你不喜欢的答案，然后撒谎说你问了什么问题。

这种现象的别称是倾听，或者“在结果已知后的假设”(假设是你对数据会向你展示什么的猜测；基本上就是你的研究问题。)

这是一个问题，因为如果你真的想测试某个问题，你会设置一个很好的实验。从一个更大的研究中获取几个数据点是不一样的。

倾听很容易隐藏:你所要做的就是永远不要发表你实验中没有成功的部分。只要写好论文，就好像你从一开始就知道你在做什么。为了防止这种情况，医学期刊经常要求研究人员 [预先注册他们的研究](https://en.wikipedia.org/wiki/Trial_registration) ，在类似[【clinicaltrials.gov】](http://clinicaltrials.gov)的地方写一段描述，解释这项研究是如何设计的，以及它将测试什么结果。认知神经科学家 Chris Chambers [在 Twitter](https://twitter.com/chrisdc77) 上建议年轻研究人员，你可以随时私下预先注册自己的研究，即使管理你实验室的人不喜欢这个主意。可以这样做的注册中心包括[aspredicted.org](https://aspredicted.org/)和 [osf.io](https://osf.io/) 。

### 发表论文的压力塑造了科学家的职业生涯

可以说，P-hacking 和 HARKing 是科学领域一个更大问题的结果，而不是原因:发表论文的压力。作为一名科学家，你的职业生涯，包括你的资金和获得终身职位或晋升的机会，通常都依赖于发表大量的研究成果——最好是在知名期刊上，最好是足以成为新闻头条的研究成果。(你会记得万辛克的研究一直是头条新闻。)

这些压力鼓励统计技巧和糟糕的研究设计，因为研究通常必须展示一些东西，最好是新的或令人惊讶的东西，才有很好的机会被发表。还记得上周的饮食研究 和我如何提到发表负面结果是不寻常的吗？我们在科学上需要更多，但这是一场艰苦的战斗。

Wansink 实验室的电子邮件 中的细节显示了发布数据的压力如何改变实验室处理数据的方式:

> 万辛克写道:“库存太多；出货量不够。”他沉思道，理想情况下，科学实验室应该像科技公司一样运作。例如，蒂姆·库克(Tim Cook)因能更快地将产品从苹果的仓库中取出并提升利润而闻名。“正如史蒂夫·乔布斯所说，‘天才之船’，”万辛克写道。
> 
> 因此，他建议，实验室应该采取一种严格的提交和再提交研究的截止日期制度，直到它有了着落。“许多这样的文件放在我们每个人的桌面上，它们就像是不为我们工作的库存，”他告诉团队。“我们有如此巨大的发展势头。这可能会让我们的生产力成为传奇。”

坚持提交论文可以最终让你的作品发表，但这对我们其他人意味着什么——那些阅读(和撰写)基于劣质研究的标题的人，这些研究被许多期刊拒绝，但又重新提交，直到最终坚持下来？

像这样的工作流程可以采取几乎任何研究，无论相关与否，并通过对其进行糟糕的分析并提交给越来越低层次的期刊，直到它在某个地方被接受，然后撰写新闻稿宣传结果，从而使其可以发表。大多数普通人都见过这一过程的最后一步:媒体上一个听起来似乎合理的结论，并保证其背后有某种科学依据。

正在调查 Wansink 实验室的异常有多少是 p-hacking 和 HARKing，而不是故意欺诈，也不是一系列诚实的错误。但是整个故事是一个警世故事，关于在媒体上出现的大量未经仔细审查的科学背后的东西。如果 Wansink 没有在 2016 年底 [写一篇博客文章](https://web.archive.org/web/20170312041524/http:/www.brianwansink.com/phd-advice/the-grad-student-who-never-said-no) 赞扬一名学生将一项“没有结果的失败研究”变成四篇发表的论文，可能没有人会发现实验室在做什么。

看到科学家们是如何处理这些新闻的，我发现这发人深省，尽管并不令人惊讶。在一次对研究人员 的非正式推特投票中，68%的人说万辛克的行为与通常的科学行为没有什么不同，他们只是更加明目张胆。心理学家皮特·埃切尔斯 [在推特上发布了一个更令人沮丧的想法:“是的，很多人都说让万辛克与众不同的是正在发生的事情的规模。我一直在想，让他与众不同的是他被抓住了。”](https://twitter.com/PeteEtchells/status/968194643304353792)